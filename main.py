import os
import requests
import datetime
import pytz
import re
import json
from bs4 import BeautifulSoup
from openai import OpenAI
import tweepy

# Zona horaria de referencia
TZ = "Europe/Madrid"

# Hashtags fijos SOLO para el tuit titular
DEFAULT_HASHTAGS = ["#TalDiaComoHoy", "#Espa√±a", "#HistoriaDeEspa√±a", "#Efem√©rides"]

# Espa√±a / Imperio como ACTOR claro (muy valorado)
SPANISH_ACTOR_TOKENS = [
    "reyes cat√≥licos",
    "imperio espa√±ol",
    "monarqu√≠a hisp√°nica",
    "monarqu√≠a espa√±ola",
    "armada espa√±ola",
    "ej√©rcito espa√±ol",
    "tercios",
    "tercios espa√±oles",
    "tercios de flandes",
    "virreinato de",
    "virreinato del",
    "virreinato de nueva espa√±a",
    "virreinato del per√∫",
    "virreinato del r√≠o de la plata",
    "virrey",
    "virreina",
    "corona de castilla",
    "corona de arag√≥n",
]

# ‚ÄúMarca Espa√±a‚Äù amplia (aqu√≠ queremos que entren muchas cosas)
SPANISH_WIDE_TOKENS = [
    "espa√±a", "espa√±ol", "espa√±ola", "espa√±oles",
    "hispania", "hispano", "hisp√°nica",
    "reino de castilla", "reino de arag√≥n",
    "castilla", "arag√≥n",
    "granada", "sevilla", "toledo", "madrid",
    "cartagena", "cartagena de indias",
    "virreinato",
    "borb√≥n", "borbones",
    "habsburgo",
    "felipe ii", "felipe iii", "felipe iv",
    "carlos v", "carlos i de espa√±a",
    "alfonso xii", "alfonso xiii", "isabel ii",
    "partido comunista de espa√±a",
    "radio barcelona",
]

# Teatro en suelo espa√±ol (puede ser guiris d√°ndose de hostias en nuestra costa)
SPANISH_THEATRE_TOKENS = [
    "m√°laga", "c√°diz", "cartagena", "cartagena de indias",
    "barcelona", "valencia", "bilbao", "santander", "la coru√±a",
    "ceuta", "melilla", "baleares", "canarias",
]

# Palabras claramente militares
MILITARY_KEYWORDS = [
    "batalla", "guerra", "combate", "frente",
    "asedio", "sitio", "conquista", "derrota", "victoria", "alzamiento",
    "revoluci√≥n", "levantamiento", "sublevaci√≥n", "bombardeo", "invasi√≥n",
    "ej√©rcito", "toma", "capitulaci√≥n", "ofensiva", "defensiva",
]

# Diplomacia / acuerdos / alianzas
DIPLO_KEYWORDS = [
    "tratado", "acuerdo", "paz", "alianza",
    "capitulaciones", "concordia",
]

# Nacionalidades extranjeras t√≠picas
FOREIGN_TOKENS = [
    "alem√°n", "alemana", "alemania", "nazi",
    "brit√°nico", "brit√°nica", "ingl√©s", "inglesa", "inglaterra",
    "estadounidense", "americano", "americana", "ee.uu", "eeuu",
    "franc√©s", "francesa", "francia",
    "italiano", "italiana", "italia",
    "ruso", "rusa", "rusia",
    "sovi√©tico", "sovi√©tica", "urss",
    "japon√©s", "japonesa", "jap√≥n",
]

# Cosas que penalizamos (cultura/pop blanda)
CULTURE_LOW_PRIORITY = [
    "premio", "premios", "concurso", "festival", "certamen",
    "programa de radio", "programa de televisi√≥n", "radio", "televisi√≥n",
    "serie", "pel√≠cula", "cine", "novela", "poeta", "cantante", "m√∫sico",
    "discogr√°fica", "disco", "√°lbum", "single"
]

# Claves de X (Twitter) desde los secrets del repositorio
TW_API_KEY = os.getenv("TWITTER_API_KEY", "")
TW_API_SECRET = os.getenv("TWITTER_API_SECRET", "")
TW_ACCESS_TOKEN = os.getenv("TWITTER_ACCESS_TOKEN", "")
TW_ACCESS_SECRET = os.getenv("TWITTER_ACCESS_TOKEN_SECRET", "")
TW_BEARER_TOKEN = os.getenv("TWITTER_BEARER_TOKEN", "")

USER_AGENT = "Efemerides_Imp_Bot/1.0 (https://github.com/efemeridesesp/tal-dia-como-hoy-es)"
WIKIDATA_API_URL = "https://www.wikidata.org/w/api.php"

# Cliente de OpenAI (usa OPENAI_API_KEY del entorno)
client = OpenAI()

# ID num√©rico de tu cuenta
TWITTER_USER_ID = "1988838626760032256"

# Fichero para almacenar hilos pendientes por 429
PENDING_FILE = "pending_tweet.json"


# ----------------- Helper para limpiar JSON con ```json ... ``` ----------------- #

def clean_json_from_markdown(raw: str) -> str:
    """
    Limpia posibles fences de Markdown tipo ```json ... ``` o ``` ... ``` y
    recorta todo lo que haya antes del primer '{' o '[' y despu√©s del √∫ltimo '}' o ']'.
    Deja solo el bloque JSON parseable.
    """
    if not isinstance(raw, str):
        raw = str(raw)

    s = raw.strip()

    # Si empieza con ``` algo, quitamos la primera l√≠nea y la √∫ltima si tambi√©n es ```
    if s.startswith("```"):
        lines = s.splitlines()
        # quitar la primera l√≠nea (``` o ```json)
        if lines:
            lines = lines[1:]
        # quitar la √∫ltima si es ``` o ```algo
        if lines and lines[-1].strip().startswith("```"):
            lines = lines[:-1]
        s = "\n".join(lines).strip()

    # Buscar el primer '{' o '['
    first_brace = s.find("{")
    first_bracket = s.find("[")
    candidates = [i for i in (first_brace, first_bracket) if i != -1]
    if candidates:
        start = min(candidates)
        s = s[start:]
    else:
        # No hay ni { ni [, devolvemos tal cual (dejar√° fallar a json.loads)
        return s

    # Buscar el √∫ltimo '}' o ']'
    last_brace = s.rfind("}")
    last_bracket = s.rfind("]")
    candidates_end = [i for i in (last_brace, last_bracket) if i != -1]
    if candidates_end:
        end = max(candidates_end) + 1
        s = s[:end]

    return s.strip()


# ----------------- Wikidata (validaci√≥n determinista de fechas) ----------------- #

def search_entity_id(label: str):
    """
    Busca un QID en Wikidata a partir de un label en espa√±ol.
    """
    if not label:
        return None

    params = {
        "action": "wbsearchentities",
        "search": label,
        "language": "es",
        "format": "json",
        "limit": 1,
    }

    try:
        resp = requests.get(WIKIDATA_API_URL, params=params, timeout=20)
        resp.raise_for_status()
        data = resp.json()
    except Exception as exc:
        print(f"‚ö†Ô∏è Error buscando entidad Wikidata para '{label}': {exc}")
        return None

    results = data.get("search", [])
    if not results:
        return None

    return results[0].get("id")


def _extract_time_values(claims, prop):
    times = []
    for claim in claims.get(prop, []):
        mainsnak = claim.get("mainsnak", {})
        datavalue = mainsnak.get("datavalue")
        if not datavalue:
            continue
        value = datavalue.get("value", {})
        time_str = value.get("time")
        if time_str:
            times.append(time_str)
    return times


def fetch_dates_for_qid(qid: str):
    """
    Devuelve un dict con posibles fechas a partir de claims de Wikidata.
    """
    if not qid:
        return {}

    params = {
        "action": "wbgetentities",
        "ids": qid,
        "props": "claims",
        "format": "json",
    }

    try:
        resp = requests.get(WIKIDATA_API_URL, params=params, timeout=20)
        resp.raise_for_status()
        data = resp.json()
    except Exception as exc:
        print(f"‚ö†Ô∏è Error consultando Wikidata para {qid}: {exc}")
        return {}

    entity = data.get("entities", {}).get(qid, {})
    claims = entity.get("claims", {})

    return {
        "P585": _extract_time_values(claims, "P585"),
        "P580": _extract_time_values(claims, "P580"),
        "P582": _extract_time_values(claims, "P582"),
        "P569": _extract_time_values(claims, "P569"),
        "P570": _extract_time_values(claims, "P570"),
    }


def normalize_ddmm(wikidata_time_str):
    """
    Convierte un time string de Wikidata a DD/MM o None si no es v√°lido.
    """
    if not wikidata_time_str:
        return None

    match = re.match(r"^[+-]?\d{4,}-(\d{2})-(\d{2})", wikidata_time_str)
    if not match:
        return None

    month, day = match.groups()
    if month == "00" or day == "00":
        return None

    return f"{day}/{month}"


def _pick_unique_ddmm(time_values):
    ddmms = []
    for time_value in time_values:
        ddmm = normalize_ddmm(time_value)
        if ddmm:
            ddmms.append(ddmm)

    unique = sorted(set(ddmms))
    if not unique:
        return None, "sin fecha exacta en Wikidata"
    if len(unique) > 1:
        return None, "ambig√ºedad de fechas en Wikidata"
    return unique[0], None


def validate_candidate_with_wikidata(candidate, today_ddmm):
    """
    Valida la fecha con Wikidata. Devuelve True si coincide con today_ddmm.
    """
    entity = candidate.get("entity")
    cand_type = candidate.get("type")
    print(f"üîç Wikidata: validando '{entity}' ({cand_type})")

    qid = search_entity_id(entity)
    if not qid:
        print("   -> Sin QID encontrado. Descartado.")
        return False

    dates = fetch_dates_for_qid(qid)

    if cand_type == "event":
        for prop in ("P585", "P580", "P582"):
            ddmm, reason = _pick_unique_ddmm(dates.get(prop, []))
            print(f"   -> {prop} ddmm: {ddmm}")
            if ddmm is None:
                if reason == "ambig√ºedad de fechas en Wikidata":
                    print(f"   -> Descartado: {reason}.")
                    return False
                continue
            if ddmm == today_ddmm:
                print("   -> Fecha coincide. V√°lido.")
                return True
            print("   -> Fecha no coincide. Descartado.")
            return False

        print("   -> Sin fecha exacta. Descartado.")
        return False

    if cand_type == "birth":
        ddmm, reason = _pick_unique_ddmm(dates.get("P569", []))
        print(f"   -> P569 ddmm: {ddmm}")
        if ddmm == today_ddmm:
            print("   -> Fecha coincide. V√°lido.")
            return True
        print(f"   -> Descartado: {reason or 'fecha no coincide'}.")
        return False

    if cand_type == "death":
        ddmm, reason = _pick_unique_ddmm(dates.get("P570", []))
        print(f"   -> P570 ddmm: {ddmm}")
        if ddmm == today_ddmm:
            print("   -> Fecha coincide. V√°lido.")
            return True
        print(f"   -> Descartado: {reason or 'fecha no coincide'}.")
        return False

    print("   -> Tipo desconocido. Descartado.")
    return False


# ----------------- Gesti√≥n de hilos pendientes ----------------- #

def load_pending_tweet():
    """Carga un hilo pendiente del fichero JSON, si existe y es v√°lido."""
    if not os.path.exists(PENDING_FILE):
        return None
    try:
        with open(PENDING_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
        headline = data.get("headline")
        followups = data.get("followups", [])
        target_ddmm = data.get("target_ddmm")
        if not isinstance(headline, str) or not headline.strip():
            return None
        if not isinstance(followups, list):
            followups = []
        followups = [str(t) for t in followups]
        if not isinstance(target_ddmm, str):
            target_ddmm = None
        return {"headline": headline, "followups": followups, "target_ddmm": target_ddmm}
    except Exception as e:
        print("‚ö†Ô∏è Error leyendo pending_tweet.json:", e)
        return None


def save_pending_tweet(headline, followups, target_ddmm):
    """Guarda un hilo pendiente en el fichero JSON."""
    try:
        data = {
            "headline": headline,
            "followups": list(followups or []),
            "target_ddmm": target_ddmm,
            "saved_at": datetime.datetime.utcnow().isoformat() + "Z",
        }
        with open(PENDING_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print("üíæ Hilo guardado en pending_tweet.json para publicar m√°s adelante.")
    except Exception as e:
        print("‚ö†Ô∏è No se pudo guardar el hilo pendiente:", e)


def clear_pending_tweet():
    """Elimina el fichero de hilo pendiente si existe."""
    try:
        if os.path.exists(PENDING_FILE):
            os.remove(PENDING_FILE)
            print("üßπ pending_tweet.json eliminado tras publicar el hilo pendiente.")
    except Exception as e:
        print("‚ö†Ô∏è No se pudo eliminar pending_tweet.json:", e)


# ----------------- Anti-repetici√≥n (timeline X) ----------------- #

def fetch_previous_events_same_day(month, day):
    """
    Lee solo los √∫ltimos tuits del usuario y detecta titulares del mismo d√≠a
    (para no repetir efem√©rides). Usa UNA sola llamada para evitar 429.
    Si hay rate limit (429) u otro error, devolvemos [] y no rompemos nada.
    """
    if not TW_BEARER_TOKEN:
        return []

    cli = tweepy.Client(bearer_token=TW_BEARER_TOKEN)
    search_prefix = f"üá™üá∏ {day} de "
    old_texts = []

    try:
        resp = cli.get_users_tweets(
            id=TWITTER_USER_ID,
            max_results=50,
            tweet_fields=["created_at", "text"],
        )
    except tweepy.errors.TooManyRequests:
        print("‚ö†Ô∏è Rate limit X (429) en get_users_tweets. Se desactiva anti-repetici√≥n hoy.")
        return []
    except Exception as e:
        print("‚ö†Ô∏è Error consultando tuits anteriores:", e)
        return []

    if not resp.data:
        return []

    for t in resp.data:
        txt = t.text
        if search_prefix in txt:
            old_texts.append(txt.lower())

    return old_texts


def event_is_repeated(event_text, old_texts):
    """
    Comprueba si un evento ya fue tratado comparando tokens clave.
    """
    t = event_text.lower()

    key_fragments = (
        SPANISH_ACTOR_TOKENS +
        SPANISH_WIDE_TOKENS +
        MILITARY_KEYWORDS +
        DIPLO_KEYWORDS
    )

    for prev in old_texts:
        matches = 0
        for k in key_fragments:
            if k in t and k in prev:
                matches += 1
        if matches >= 2:
            return True

    return False


# ----------------- Anti-contradicciones (hilo) ----------------- #

def detect_and_fix_contradictions(headline, followups, event_text):
    """
    Detecta contradicciones internas usando modelo y reescribe los tuits conflictivos.
    """
    all_tweets = [headline] + followups

    prompt = f"""
Analiza estos tuits y detecta contradicciones internas en fechas, cifras, nombres, lugares o hechos.

EFEM√âRIDE ORIGINAL:
\"\"\"{event_text}\"\"\"

TUITS DEL HILO:
{json.dumps(all_tweets, ensure_ascii=False, indent=2)}

Tu tarea:
- Si hay contradicciones, corrige los tuits m√≠nimos necesarios para que todo sea coherente con la efem√©ride original.
- Respeta el estilo, tono y longitud aproximada.

Devuelve EXCLUSIVAMENTE un JSON con la siguiente forma:
{{
  "fixed": ["tuit1", "tuit2", "..."]
}}
No a√±adas nada m√°s.
"""

    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {"role": "system", "content": "Corrige contradicciones internas respetando el estilo original y la efem√©ride proporcionada."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2,
        max_tokens=800
    )

    raw = resp.choices[0].message.content.strip()
    raw_clean = clean_json_from_markdown(raw)

    try:
        data = json.loads(raw_clean)
        fixed = data.get("fixed", [])
        if isinstance(fixed, list) and len(fixed) == len(all_tweets):
            return fixed[0], fixed[1:]
    except Exception:
        print("‚ö†Ô∏è No se ha podido parsear el JSON de correcci√≥n de contradicciones.")
        print("Contenido bruto devuelto por OpenAI:")
        print(raw)

    return headline, followups


# ----------------- Utilidades de fecha ----------------- #

def today_info():
    """Devuelve (a√±o, mes, d√≠a, nombre_mes) en Europa/Madrid."""
    tz = pytz.timezone(TZ)
    now = datetime.datetime.now(tz)
    year = now.year
    month = now.month
    day = now.day

    meses = [
        "", "enero", "febrero", "marzo", "abril", "mayo", "junio",
        "julio", "agosto", "septiembre", "octubre", "noviembre", "diciembre"
    ]
    month_name = meses[month]
    return year, month, day, month_name


# ----------------- Scrapers web (ya no usados en main, se dejan por si acaso) ----------------- #

def fetch_hoyenlahistoria_events():
    url = "https://www.hoyenlahistoria.com/efemerides.php"
    headers = {"User-Agent": USER_AGENT}

    resp = requests.get(url, headers=headers, timeout=25)
    resp.raise_for_status()

    soup = BeautifulSoup(resp.text, "html.parser")
    events = []

    for li in soup.find_all("li"):
        text = " ".join(li.stripped_strings)
        if not text:
            continue

        m = re.match(r"^(\d+)\s*(a\.C\.)?\s*(.*)", text)
        if not m:
            continue

        year_str, era, rest = m.groups()
        try:
            year = int(year_str)
        except ValueError:
            continue

        if era:
            year = -year

        body = rest.strip()
        if not body:
            continue

        events.append({
            "year": year,
            "text": body,
            "raw": text,
            "source": "hoyenlahistoria"
        })

    return events


def fetch_nuestrahistoria_events_for_today(today_day, today_month_name):
    headers = {"User-Agent": USER_AGENT}
    events = []
    month = today_month_name.lower()
    day = today_day

    urls = [
        "https://nuestrahistoria.es/efemerides/",
        "https://nuestrahistoria.es/efemerides/2/",
        "https://nuestrahistoria.es/efemerides/3/",
    ]

    pattern = re.compile(
        rf"Tal d√≠a como hoy,\s*el\s+{day}\s+de\s+{month}[^\d]*(\d{{3,4}})(.*?)(?=Tal d√≠a como hoy, el|\Z)",
        re.IGNORECASE | re.DOTALL,
    )

    for url in urls:
        try:
            resp = requests.get(url, headers=headers, timeout=25)
            resp.raise_for_status()
        except Exception as e:
            print(f"‚ö†Ô∏è Error accediendo a {url}:", e)
            continue

        soup = BeautifulSoup(resp.text, "html.parser")
        full_text = soup.get_text(" ", strip=True)

        for m in pattern.finditer(full_text):
            year_str = m.group(1)
            try:
                year = int(year_str)
            except ValueError:
                continue
            snippet = m.group(0).strip()
            events.append({
                "year": year,
                "text": snippet,
                "raw": snippet,
                "source": "nuestrahistoria",
            })

    return events


def fetch_espanaenlahistoria_events_for_today(today_day, today_month_name):
    headers = {"User-Agent": USER_AGENT}
    events = []
    month = today_month_name.lower()
    day = today_day

    base = "https://espanaenlahistoria.org/efemerides/"
    urls = [
        base,
        base + "page/2/",
        base + "page/3/",
    ]

    pattern = re.compile(
        rf"\({day}\s+{month}\s+(\d{{3,4}})\)",
        re.IGNORECASE,
    )

    for url in urls:
        try:
            resp = requests.get(url, headers=headers, timeout=25)
            resp.raise_for_status()
        except Exception as e:
            print(f"‚ö†Ô∏è Error accediendo a {url}:", e)
            continue

        soup = BeautifulSoup(resp.text, "html.parser")
        full_text = soup.get_text(" ", strip=True)

        for m in pattern.finditer(full_text):
            year_str = m.group(1)
            try:
                year = int(year_str)
            except ValueError:
                continue

            start = max(0, m.start() - 200)
            end = min(len(full_text), m.end() + 200)
            snippet = full_text[start:end].strip()

            events.append({
                "year": year,
                "text": snippet,
                "raw": snippet,
                "source": "espanaenlahistoria",
            })

    return events


# ----------------- NUEVO: fuente principal ‚Üí OpenAI (lista de efem√©rides) ----------------- #

def fetch_openai_events_for_today(today_year, today_month, today_day, today_month_name):
    """
    Pide a OpenAI una lista de efem√©rides del d√≠a centradas en Espa√±a / Imperio,
    devuelve lista de dicts con: year, text, raw, source="openai".
    """
    today_str = f"{today_day} de {today_month_name} de {today_year}"

    prompt = f"""
Fecha de hoy: {today_str}.

Genera una lista de entre 20 y 40 efem√©rides hist√≥ricas relevantes para la historia de Espa√±a y del Imperio espa√±ol
que ocurrieran un {today_day} de {today_month_name}, en cualquier a√±o.

Condiciones:
- Deben ser hechos de tipo militar, pol√≠tico, diplom√°tico, exploraciones, conquistas, tratados, cambios de r√©gimen,
  grandes decisiones de Estado, fundaciones importantes, etc.
- Espa√±a (o sus reinos hist√≥ricos: Castilla, Arag√≥n, Navarra, la Monarqu√≠a Hisp√°nica, el Imperio espa√±ol, etc.)
  debe ser actor principal o claramente protagonista.
- Redacta todo en espa√±ol.

FORMATO DE RESPUESTA (OBLIGATORIO):
    Devuelve EXCLUSIVAMENTE un JSON con esta estructura:

{{
  "events": [
    {{
      "year": 1580,
      "type": "event",
      "entity": "Tratado de Lisboa",
      "text": "texto breve describiendo la efem√©ride..."
    }},
    {{
      "year": 1643,
      "type": "birth",
      "entity": "Carlos II de Espa√±a",
      "text": "..."
    }}
  ]
}}

No a√±adas comentarios fuera del JSON.
"""

    completion = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {
                "role": "system",
                "content": (
                    "Eres un historiador especializado en Espa√±a y en el Imperio espa√±ol. "
                    "Generas efem√©rides precisas y relevantes siguiendo estrictamente el formato pedido."
                ),
            },
            {"role": "user", "content": prompt},
        ],
        temperature=0.5,
        max_tokens=1200,
    )

    raw = completion.choices[0].message.content.strip()
    raw_clean = clean_json_from_markdown(raw)

    events = []
    try:
        data = json.loads(raw_clean)

        # Puede venir como {"events":[...]} o como lista directa [...]
        if isinstance(data, dict):
            items = data.get("events", [])
        else:
            items = data

        if isinstance(items, list):
            for item in items:
                if not isinstance(item, dict):
                    continue
                year = item.get("year")
                cand_type = item.get("type")
                entity = item.get("entity")
                desc = (
                    item.get("text")
                    or item.get("description")
                    or item.get("texto")
                )
                try:
                    year_int = int(year)
                except (TypeError, ValueError):
                    continue
                if not isinstance(desc, str):
                    continue
                if cand_type not in {"event", "birth", "death"}:
                    continue
                if not isinstance(entity, str) or not entity.strip():
                    continue
                desc = desc.strip()
                if not desc:
                    continue
                events.append({
                    "year": year_int,
                    "type": cand_type,
                    "entity": entity.strip(),
                    "text": desc,
                    "raw": desc,
                    "source": "openai",
                })
    except Exception as e:
        print("‚ö†Ô∏è No se ha podido parsear el JSON de efem√©rides desde OpenAI:", e)
        print("Contenido bruto devuelto por OpenAI:")
        print(raw)

    return events


# ----------------- Scoring ‚Äúimperial‚Äù ----------------- #

def compute_score(ev):
    text = ev["text"]
    t_low = text.lower()
    year = ev["year"]

    score = 0.0

    has_spanish_actor = any(tok in t_low for tok in SPANISH_ACTOR_TOKENS)
    has_spanish_wide = any(tok in t_low for tok in SPANISH_WIDE_TOKENS)
    has_spanish_theatre = any(tok in t_low for tok in SPANISH_THEATRE_TOKENS)

    has_military = any(kw in t_low for kw in MILITARY_KEYWORDS)
    has_diplomatic = any(kw in t_low for kw in DIPLO_KEYWORDS)
    has_foreign = any(tok in t_low for tok in FOREIGN_TOKENS)

    if has_spanish_actor:
        score += 35

    if has_spanish_wide:
        score += 18

    if has_spanish_theatre:
        score += 5

    if has_military:
        score += 12

    if has_diplomatic:
        score += 8

    for kw in CULTURE_LOW_PRIORITY:
        if kw in t_low:
            score -= 12

    if 1400 <= year <= 1899:
        score += 5

    if has_military and has_foreign and not has_spanish_actor and not has_diplomatic:
        score -= 40

    ev["score"] = score
    ev["has_spanish_actor"] = has_spanish_actor
    ev["has_spanish_wide"] = has_spanish_wide
    ev["has_spanish_theatre"] = has_spanish_theatre
    ev["has_military"] = has_military
    ev["has_diplomatic"] = has_diplomatic
    ev["has_foreign"] = has_foreign


def choose_best_event(events, old_texts):
    """
    Elige el evento con mayor score seg√∫n compute_score, evitando repetidos.
    """
    candidates = []

    for ev in events:
        if event_is_repeated(ev["text"], old_texts):
            continue
        compute_score(ev)
        candidates.append(ev)

    if not candidates:
        return None

    best = max(candidates, key=lambda e: e["score"])
    return best


def choose_best_verified_event(events, old_texts, today_ddmm):
    """
    Elige el mejor evento por score y lo valida con Wikidata.
    Si no pasa validaci√≥n, prueba el siguiente.
    """
    candidates = []

    for ev in events:
        if event_is_repeated(ev["text"], old_texts):
            continue
        compute_score(ev)
        candidates.append(ev)

    if not candidates:
        return None

    candidates.sort(key=lambda e: e["score"], reverse=True)

    for ev in candidates:
        if validate_candidate_with_wikidata(ev, today_ddmm):
            return ev
        print(f"‚ö†Ô∏è Evento descartado por Wikidata: {ev['text']}")

    return None


# ----------------- Generaci√≥n de TEXTO con OpenAI ----------------- #

def generate_headline_tweet(today_year, today_month_name, today_day, event):
    """
    Genera el tuit TITULAR (con banderita, fecha, a√±o del suceso y hashtags).
    """
    today_str = f"{today_day} de {today_month_name} de {today_year}"
    event_year = event["year"]
    event_text = event["text"]
    hashtags = " ".join(DEFAULT_HASHTAGS)

    prompt_user = f"""
Fecha de hoy: {today_str}.
Efem√©ride seleccionada (a√±o {event_year}) procedente de un listado de efem√©rides hist√≥ricas:

\"\"\"{event_text}\"\"\"

Escribe UN SOLO tuit en espa√±ol siguiendo EXACTAMENTE este formato general:

"üá™üá∏ {today_str}: En tal d√≠a como hoy del a√±o {event_year}, ... {hashtags}"

Reglas importantes:
- M√°ximo 260 caracteres en total (incluyendo los hashtags y la banderita).
- Debe empezar EXACTAMENTE por: "üá™üá∏ {today_str}: En tal d√≠a como hoy del a√±o {event_year},"
  y a continuaci√≥n una frase breve que resuma el hecho hist√≥rico.
- Tono divulgativo, con cierto orgullo por la historia de Espa√±a y su Imperio, sin m√°s emojis, sin URLs y sin mencionar la fuente.
- No a√±adas m√°s hashtags que estos cuatro ni cambies su texto: {hashtags}.
- No uses saltos de l√≠nea, todo debe ir en una sola frase.
"""

    completion = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {
                "role": "system",
                "content": (
                    "Eres un divulgador de historia de Espa√±a y del Imperio espa√±ol. "
                    "Escribes tuits breves, claros y con ligero tono √©pico, respetando estrictamente el formato pedido."
                ),
            },
            {"role": "user", "content": prompt_user},
        ],
        temperature=0.4,
        max_tokens=200,
    )

    text = completion.choices[0].message.content.strip()

    if len(text) > 275:
        text = text[:272].rstrip() + "..."

    prefix = f"üá™üá∏ {today_str}: En tal d√≠a como hoy del a√±o {event_year},"
    if not text.startswith(prefix):
        core_desc = event_text
        if len(core_desc) > 150:
            core_desc = core_desc[:147].rstrip() + "..."
        text = f"{prefix} {core_desc} {hashtags}"
        if len(text) > 275:
            text = text[:272].rstrip() + "..."

    return text


def generate_followup_tweets(today_year, today_month_name, today_day, event):
    """
    Genera entre 1 y 5 tuits adicionales que ir√°n como respuestas (hilo).
    """
    today_str = f"{today_day} de {today_month_name} de {today_year}"
    event_year = event["year"]
    event_text = event["text"]

    prompt_user = f"""
Fecha de hoy: {today_str}.
Efem√©ride seleccionada (a√±o {event_year}):

\"\"\"{event_text}\"\"\"

Vas a escribir un HILO que contin√∫a el tuit titular (que ya dice:
"üá™üá∏ {today_str}: En tal d√≠a como hoy del a√±o {event_year}, ...").

Tu tarea:
- Redacta entre 1 y 5 tuits adicionales (no el titular) que expliquen:
  - qu√© supuso este hecho para Espa√±a o para el Imperio espa√±ol,
  - o por qu√© la figura implicada fue importante para Espa√±a/Imperio,
  - consecuencias a corto y largo plazo,
  - contexto hist√≥rico relevante (sin irte del tema).
- Cada tuit debe:
  - estar en espa√±ol,
  - tener como m√°ximo 260 caracteres,
  - NO empezar por la fecha ni por "En tal d√≠a como hoy...",
  - NO incluir hashtags,
  - NO incluir emojis,
  - ser autosuficiente pero encajar como parte de una peque√±a historia enlazada.

FORMATO DE RESPUESTA:
- Devu√©lveme EXCLUSIVAMENTE un JSON con una lista de strings, por ejemplo:
  ["texto del tuit 2", "texto del tuit 3", "..."]
- No a√±adas nada fuera del JSON.
"""

    completion = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {
                "role": "system",
                "content": (
                    "Eres un divulgador de historia de Espa√±a y del Imperio espa√±ol. "
                    "Escribes hilos de X breves, claros y ordenados, respetando estrictamente el formato pedido."
                ),
            },
            {"role": "user", "content": prompt_user},
        ],
        temperature=0.6,
        max_tokens=400,
    )

    raw = completion.choices[0].message.content.strip()
    raw_clean = clean_json_from_markdown(raw)

    tweets = []
    try:
        data = json.loads(raw_clean)

        # Puede venir como lista directa ["...", "..."]
        # o como {"tweets":[...]} o similar
        if isinstance(data, list):
            items = data
        elif isinstance(data, dict):
            # buscamos una clave razonable
            if "tweets" in data and isinstance(data["tweets"], list):
                items = data["tweets"]
            elif "hilo" in data and isinstance(data["hilo"], list):
                items = data["hilo"]
            else:
                # Intentar coger el primer valor que sea lista
                listas = [v for v in data.values() if isinstance(v, list)]
                items = listas[0] if listas else []
        else:
            items = []

        if isinstance(items, list):
            for item in items:
                if isinstance(item, str):
                    text = item.strip()
                elif isinstance(item, dict):
                    text = str(
                        item.get("text")
                        or item.get("contenido")
                        or item.get("description")
                        or ""
                    ).strip()
                else:
                    continue

                if not text:
                    continue

                if len(text) > 275:
                    text = text[:272].rstrip() + "..."
                tweets.append(text)
    except Exception as e:
        print("‚ö†Ô∏è No se ha podido parsear el JSON de followups:", e)
        print("Contenido bruto devuelto por OpenAI:")
        print(raw)
        tweets = []

    if len(tweets) > 5:
        tweets = tweets[:5]

    return tweets


# ----------------- Publicaci√≥n en X (API v2) ----------------- #

def get_twitter_client():
    if not (TW_API_KEY and TW_API_SECRET and TW_ACCESS_TOKEN and TW_ACCESS_SECRET and TW_BEARER_TOKEN):
        raise RuntimeError("Faltan claves de Twitter/X en las variables de entorno.")

    print(
        "DEBUG Twitter keys present:",
        bool(TW_API_KEY),
        bool(TW_API_SECRET),
        bool(TW_ACCESS_TOKEN),
        bool(TW_ACCESS_SECRET),
        bool(TW_BEARER_TOKEN),
    )

    client_tw = tweepy.Client(
        consumer_key=TW_API_KEY,
        consumer_secret=TW_API_SECRET,
        access_token=TW_ACCESS_TOKEN,
        access_token_secret=TW_ACCESS_SECRET,
        bearer_token=TW_BEARER_TOKEN,
    )
    return client_tw


def post_thread(headline, followups):
    """
    Publica el tuit titular y, si hay followups, va respondiendo en hilo.
    """
    client_tw = get_twitter_client()

    resp = client_tw.create_tweet(text=headline)
    print("DEBUG create_tweet (headline) response:", resp)
    tweet_id = resp.data.get("id")
    if not tweet_id:
        print("‚ö†Ô∏è No se obtuvo ID del tuit titular, no se puede continuar el hilo.")
        return

    parent_id = tweet_id
    for t in followups:
        try:
            resp = client_tw.create_tweet(text=t, in_reply_to_tweet_id=parent_id)
            print("DEBUG create_tweet (reply) response:", resp)
            new_id = resp.data.get("id")
            if new_id:
                parent_id = new_id
        except Exception as e:
            print("‚ùå Error publicando un tuit de hilo:", e)
            break


def try_publish_pending_thread(pending):
    """Intenta publicar un hilo pendiente. Devuelve True si se public√≥ o False si se mantiene."""
    print("üì® Hay un hilo pendiente en pending_tweet.json. Intentando publicarlo primero...")
    try:
        post_thread(pending["headline"], pending.get("followups", []))
        print("‚úÖ Hilo pendiente publicado correctamente.")
        clear_pending_tweet()
        return True
    except tweepy.errors.TooManyRequests:
        print("‚ùå Rate limit 429 al publicar el hilo pendiente. Se mantiene en cola y se aborta hoy.")
        return False
    except Exception as e:
        print("‚ùå Error publicando el hilo pendiente:", e)
        print("Se mantiene en cola y se aborta hoy para no perderlo.")
        return False


# ----------------- Main ----------------- #

def main():
    today_year, today_month, today_day, today_month_name = today_info()
    today_ddmm = f"{today_day:02d}/{today_month:02d}"

    print(f"Hoy es {today_day}/{today_month}/{today_year} ({today_month_name}).")

    # 0) Si hay un hilo pendiente de d√≠as anteriores, intentamos publicarlo primero
    pending = load_pending_tweet()
    if pending:
        pending_ddmm = pending.get("target_ddmm")
        if pending_ddmm != today_ddmm:
            print(
                "‚ö†Ô∏è Hay un hilo pendiente, pero su fecha objetivo no coincide con hoy. "
                "No se publicar√° para evitar errores de dd/mm."
            )
        else:
            if not try_publish_pending_thread(pending):
                return

    # 1) Fuente principal: OpenAI genera efem√©rides del d√≠a
    try:
        events = fetch_openai_events_for_today(today_year, today_month, today_day, today_month_name)
        print(f"Se han generado {len(events)} efem√©rides desde OpenAI para {today_day}/{today_month}/{today_year}.")
    except Exception as e:
        print("‚ùå Error generando efem√©rides desde OpenAI:", e)
        events = []

    if not events:
        print("No hay eventos generados para hoy. No se publicar√° tuit.")
        return

    # 2) Anti-repetici√≥n bas√°ndose en tu timeline reciente
    old_texts = fetch_previous_events_same_day(today_month, today_day)

    # 3) Elegir el mejor evento seg√∫n scoring y evitando repetidos
    best = choose_best_verified_event(events, old_texts, today_ddmm)
    if not best:
        print("No se ha podido seleccionar una efem√©ride v√°lida tras verificaci√≥n. No se publicar√° tuit.")
        return

    print("Evento elegido:")
    print(f"- A√±o: {best['year']}")
    print(f"- Tipo: {best['type']}")
    print(f"- Entidad: {best['entity']}")
    print(f"- Texto: {best['text']}")
    print(f"- Score: {best.get('score', 'N/A')}")
    print(
        f"- ActorEsp: {best.get('has_spanish_actor')}, "
        f"EspAmplio: {best.get('has_spanish_wide')}, "
        f"TeatroEsp: {best.get('has_spanish_theatre')}, "
        f"Militar: {best.get('has_military')}, "
        f"Diplom√°tico: {best.get('has_diplomatic')}, "
        f"Extranjeros: {best.get('has_foreign')}"
    )

    # 4) Generar el tuit titular
    try:
        headline = generate_headline_tweet(today_year, today_month_name, today_day, best)
    except Exception as e:
        print("‚ùå Error al generar el tuit titular con OpenAI:", e)
        return

    if not headline or not isinstance(headline, str) or len(headline.strip()) == 0:
        print("‚ùå OpenAI devolvi√≥ un titular vac√≠o o inv√°lido. Abortando para evitar publicar un tuit en blanco.")
        return

    print("Tuit titular generado:")
    print(headline)
    print(f"Largo: {len(headline)} caracteres")

    # 5) Generar los tuits de hilo (2¬∫ a 6¬∫)
    try:
        followups = generate_followup_tweets(today_year, today_month_name, today_day, best)
    except Exception as e:
        print("‚ö†Ô∏è Error generando los tuits de hilo con OpenAI:", e)
        followups = []

    print(f"Se han generado {len(followups)} tuits adicionales para el hilo.")
    for i, t in enumerate(followups, start=2):
        print(f"[Tuit {i}] {t} (len={len(t)})")

    # 6) Anti-contradicciones
    headline, followups = detect_and_fix_contradictions(headline, followups, best["text"])

    # 7) Publicar hilo en X
    try:
        post_thread(headline, followups)
        print("‚úÖ Hilo publicado correctamente.")
    except tweepy.errors.TooManyRequests:
        print("‚ö†Ô∏è 429 Too Many Requests al publicar el hilo de hoy. Se guarda como pendiente.")
        save_pending_tweet(headline, followups, today_ddmm)
        return
    except Exception as e:
        print("‚ùå Error publicando el hilo en Twitter/X:", e)
        raise


def run_wikidata_validation_smoke_test():
    """
    Smoke test manual: Felipe III de Espa√±a NO coincide con 07/01.
    """
    candidate = {
        "type": "death",
        "entity": "Felipe III de Espa√±a",
        "year": 1621,
        "text": "Fallecimiento de Felipe III de Espa√±a.",
    }
    today_ddmm = "07/01"
    is_valid = validate_candidate_with_wikidata(candidate, today_ddmm)
    print(f"Resultado test Felipe III (death) vs {today_ddmm}: {is_valid}")


if __name__ == "__main__":
    if os.getenv("RUN_WIKIDATA_TEST") == "1":
        run_wikidata_validation_smoke_test()
    else:
        main()
